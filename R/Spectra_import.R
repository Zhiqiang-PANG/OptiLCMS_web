#'Constructs a dataSet object for storing data 
#'@description This functions handles the construction of a mSetObj object for storing data for further processing and analysis.
#'It is necessary to utilize this function to specify to MetaboAnalystR the type of data and the type of analysis you will perform. 
#'@usage InitDataObjects(data.type, anal.type, paired=FALSE)
#'@param data.type The type of data, either list (Compound lists), conc (Compound concentration data), 
#'specbin (Binned spectra data), pktable (Peak intensity table), nmrpeak (NMR peak lists), mspeak (MS peak lists), 
#'or msspec (MS spectra data)
#'@param anal.type Indicate the analysis module to be performed: stat, pathora, pathqea, msetora, msetssp, msetqea, ts, 
#'cmpdmap, smpmap, or pathinteg
#'@param paired Indicate if the data is paired or not. Logical, default set to FALSE
#'@author Jeff Xia \email{jeff.xia@mcgill.ca}
#'McGill University, Canada
#'License: GNU GPL (>= 2)
#'@export
#'@import methods
#'@import BiocParallel
#'@importFrom  Cairo CairoFonts
#'@examples 
#' library(OptiLCMS);
#' mSet<-InitDataObjects("spec", "raw", FALSE)

InitDataObjects <- function(data.type, anal.type, paired=FALSE){
  
  if(anal.type == "raw" & data.type == "spec") {
    cat("OptiLCMS R objects initialized ...\n");
    return(new("mSet"))
  }
  
}

#' Import raw MS data
#' @description This function handles the reading in of
#' raw MS data (.mzML, .CDF and .mzXML). Users must set
#' their working directory to the folder containing their raw
#' data, divided into two subfolders named their desired group labels. The
#' function will output two chromatograms into the user's working directory, a
#' base peak intensity chromatogram (BPIC) and a total ion
#' chromatogram (TIC). Further, this function sets the number of cores
#' to be used for parallel processing. It first determines the number of cores
#' within a user's computer and then sets it that number/2.
#' @param mSet mSet Object, can be optional. Usually generated by InitDataObjects("spec", "raw", FALSE) before the data import.
#' @param foldername Character, input the file path to the folder containing
#' the raw MS spectra to be processed.
#' @param mode Character, the data input mode. Default is "onDisk" to avoid memory crash. "inMemory" will
#' absorb data into the memory.
#' @param ncores Numeric, a value used to defined the parallel cores.
#' @param plotSettings List, plotting parameters produced by SetPlotParam Function. "plot.opts" can be added through this
#' function for samples numbers for plotting. Defalut is "default", "all" will apply all samples for plotting and may cause
#' memory crash, especially for large sample dataset.
#' @param running.controller The resuming pipeline running controller. Optional. Don't need to define by hand.
#' @author Zhiqiang Pang \email{zhiqiang.pang@mail.mcgill.ca}, Jasmine Chong \email{jasmine.chong@mail.mcgill.ca},
#' Mai Yamamoto \email{yamamoto.mai@mail.mcgill.ca}, and Jeff Xia \email{jeff.xia@mcgill.ca}
#' McGill University, Canada
#' License: GNU GPL (>= 2)
#' @export
#' @import MSnbase
#' @import BiocParallel
#' @import parallel
#' @importFrom tools file_path_as_absolute
#' @importFrom Cairo Cairo
#' @examples 
#' ## load googledrive package to download example data
#' # library("googledrive");
#'
#' ## Set data folder
#' # data_folder_Sample <- "~/Data_IBD";
#' # data_folder_QC <- "~/Data_IBD/QC";
#' # temp <- tempfile(fileext = ".zip");
#'
#' ## Please authorize the package to download the data from web
#' # dl <- drive_download(as_id("1CjEPed1WZrwd5T3Ovuic1KVF-Uz13NjO"), path = temp, overwrite = TRUE);
#' # out <- unzip(temp, exdir = data_folder_Sample);
#' # out;
# 
#' #### Running as regular procedure: step by step
#' ## Extract ROI for parameters' optimization
#' # mSet <- PerformROIExtraction(datapath = data_folder_QC, rt.idx = 0.95, plot = F, rmConts = F);
#' ## Perform the optimization
#' # best_parameters <- PerformParamsOptimization(mSet = mSet, SetPeakParam(), ncore = 4);
#' ## Perform data import of all samples
#' # mSet <- ImportRawMSData(mSet = mSet, foldername = data_folder_Sample, 
#' #                         plotSettings = SetPlotParam(Plot=T));
#' ## Perform peak profiling
#' # mSet <- PerformPeakProfiling(mSet = mSet, Params = param, plotSettings = SetPlotParam(Plot=T));
#' ## Set annotation parameters
#' # annParams <- SetAnnotationParam(polarity = 'negative', mz_abs_add = 0.025);
#' ## Perform peak annotation
#' # mSet <- PerformPeakAnnotation(mSet = mSet, annotaParam = annParams, ncore =1);
#' ## Format the peak table
#' # maPeaks <- FormatPeakList(mSet = mSet, annParams, filtIso =F, 
#' #                           filtAdducts = FALSE, missPercent = 1);
#' 
#' #### Running as resumable procedure: seamless pipeline
#' ## load googledrive package to download example data
#' # library("googledrive");
#'
#' # Set data folder
#' # data_folder_Sample <- "~/Data_IBD";
#' # temp <- tempfile(fileext = ".zip");
#'
#' # Please authorize the package to download the data from web
#' # dl <- drive_download(as_id("1CjEPed1WZrwd5T3Ovuic1KVF-Uz13NjO"), path = temp, overwrite = TRUE);
#' # out <- unzip(temp, exdir = data_folder_Sample);
#' # out;
# 
#' #### Running as resumable procedure: seamless pipeline
#' ## Initialize running plan
#' # plan <- InitializaPlan("raw_opt","~/Data_IBD/")
#' ## define/set running plan
#' # plan <- running.plan(plan,
#' #                      data_folder_QC <- "~/Data_IBD/QC",
#' #                      mSet <- PerformROIExtraction(datapath = data_folder_QC, 
#' #                                                   rt.idx = 0.95, plot = F, 
#' #                                                   rmConts = F, 
#' #                                                   running.controller = rc),
#' #                      param_initial <- SetPeakParam(),
#' #                      best_parameters <- PerformParamsOptimization(mSet = mSet, 
#' #                                                   param_initial, ncore = 2, 
#' #                                                   running.controller = rc),
#' #                      data_folder_Sample <- '',
#' #                      param <- best_parameters,
#' #                      plotSettings1 <- SetPlotParam(Plot=T),
#' #                      plotSettings2 <- SetPlotParam(Plot=T),
#' #                      mSet <- ImportRawMSData(mSet = mSet, 
#' #                                              foldername = data_folder_Sample, 
#' #                                              plotSettings = plotSettings1, 
#' #                                              running.controller = rc),
#' #                      mSet <- PerformPeakProfiling(mSet = mSet, 
#' #                                              Params = param, 
#' #                                              plotSettings = plotSettings2, 
#' #                                              running.controller = rc),
#' #                      annParams <- SetAnnotationParam(polarity = 'negative', 
#' #                                              mz_abs_add = 0.025),
#' #                      mSet <- PerformPeakAnnotation(mSet = mSet, 
#' #                                              annotaParam = annParams, 
#' #                                              ncore =1, 
#' #                                              running.controller = rc),
#' #                      maPeaks <- FormatPeakList(mSet = mSet, annParams, filtIso =F, 
#' #                                              filtAdducts = FALSE ,
#' #                                              missPercent = 1));
#' ## Execute the defined plan
#' # ExecutePlan(plan)

ImportRawMSData <-
  function(mSet = NULL,
           foldername,
           mode = "onDisk",
           ncores = 4,
           plotSettings,
           running.controller = NULL) {
    
    if (!dir.exists(foldername) & .on.public.web) {
      foldername <- "/home/glassfish/projects/MetaboDemoRawData/upload"
    } else if(!dir.exists(foldername)){
      folderPath <- paste0(getwd(),foldername);
    } else if(dir.exists(foldername)){
      folderPath <- foldername;
    } else {
      stop("Wrong folername has been provided ! Please check !")
    }

    foldername <- tools::file_path_as_absolute(folderPath);

    if(missing(mSet)){
      message("No initialized mSet found, will initialize one automatically !")
      mSet <- new("mSet")
    } else if(is.null(mSet)){
      message("Not a real initialized mSet found, will re-initialize one automatically !")
      mSet <- new("mSet")
    }
    
    #Build Running plan for data import - Indentify the controller
    if (is.null(running.controller)) {
      c1 <- TRUE;
      c2 <- TRUE;
      plan_switch <- FALSE;
    } else {
      plan_switch <- TRUE;
      c1 <-
        running.controller@data_import[["c1"]] # used to control data import
      c2 <-
        running.controller@data_import[["c2"]] # used to control plotting option
    }
    
    .optimize_switch <<- FALSE;

    start.time <- Sys.time()
    msg.vec <<- vector(mode = "character")
    msg <- c("The uploaded files are raw MS spectra.")
    
    # the "upload" folder should contain two subfolders (groups, i.e. Healthy vs. Disease)
    # each subfolder must contain samples (.mzML/.CDF/.mzXML files)
    
    MessageOutput(mes = "Step 2/6: Start to import the spectrum! \nThis step will take a short time...",
                  ecol = "\n",
                  progress = 21.0)
    
    files <-
      dir(
        foldername,
        pattern = ".mzML|.mzml|.cdf|.mzXML|.mzxml|.mzData|.CDF",
        recursive = T,
        full.names = TRUE
      )
    
    # Centroid check & filter
    Centroididx <- unname(sapply(files, CentroidCheck));
    files <- files[Centroididx];
    
    if (length(files) == 0) {
      MessageOutput(
        mes = paste0(
          "<font color=\"red\">",
          "\nERROR: No standard MS file found ! Please check the extension of your data.",
          "</font>"
        ),
        ecol = "\n",
        progress = NULL
      )
      stop()
      
    } else if (length(files) < 3) {
      MessageOutput(
        mes = paste0(
          "<font color=\"red\">",
          "\nERROR: At least 3 samples should be provided.",
          "</font>"
        ),
        ecol = "\n",
        progress = NULL
      )
    }
    
    count_total_sample <<- length(files);
    count_current_sample <<- 0;
    toRemove = vector();
    
    # Update first
    if(length(mSet@rawfiles) == 0){
      rawfilenms <- basename(files);
    } else {
      rawfilenms <- basename(mSet@rawfiles);
    }
    
    for (i in 1:length(files)) {
      file = basename(files[i])
      if (!(file %in% rawfilenms)) {
        toRemove = c(toRemove, files[i])
      }
    }
    
    toKeepInx = !(files %in% toRemove);
    files = files[toKeepInx];
    
    snames <- gsub("\\.[^.]*$", "", basename(files))
    msg <- c(msg, paste("A total of ", length(files), "samples were found."))
    sclass <- gsub("^\\.$", "sample", dirname(files))
    
    scomp <- strsplit(substr(sclass, 1, min(nchar(sclass))), "", fixed = TRUE)
    scomp <- matrix(c(scomp, recursive = TRUE), ncol = length(scomp))
    
    i <- 1
    while (all(scomp[i, 1] == scomp[i, -1]) && i < nrow(scomp)) {
      i <- i + 1
    }
    
    i <-
      min(i, tail(c(0, which(
        scomp[1:i, 1] == .Platform$file.sep
      )), n = 1) + 1)
    
    if (i > 1 && i <= nrow(scomp)) {
      sclass <- substr(sclass, i, max(nchar(sclass)))
    }
    
    if (.on.public.web &
        unique(sclass)[1] == "upload" &
        length(unique(sclass)) == 1) {
      sclass <- rep("Unknown", length(sclass))
    }
    # some sanity check before proceeds
    sclass <- as.factor(sclass);
    SetClass(sclass);
    
    # # check for unique sample names
    # if (length(unique(snames)) != length(snames)) {
    #   AddErrMsg("Duplicate sample names are not allowed!")
    #   dup.nm <- paste(snames[duplicated(snames)], collapse = " ")
    #   AddErrMsg("Duplicate sample names are not allowed!")
    #   AddErrMsg(dup.nm)
    #   return(0)
    # }
    # 
    pd <- data.frame(
      sample_name = snames,
      sample_group = sclass,
      stringsAsFactors = FALSE
    )
    
    if (!.on.public.web) {
      cores <- parallel::detectCores()
      if (missing(ncores)) {
        num_cores <- ceiling(cores * 2 / 3)
      } else{
        ncores -> num_cores
      }
      
      cat(paste0("The number of CPU cores to be used is set to ", num_cores, ".","\n"))
      
      if (.Platform$OS.type == "unix") {
        BiocParallel::register(BiocParallel::bpstart(BiocParallel::MulticoreParam(num_cores)))
      } else {
        # for windows
        BiocParallel::register(BiocParallel::bpstart(BiocParallel::SnowParam(num_cores)))
      }
      
    } else {
      num_cores <- 2
      cat(paste0("The number of CPU cores to be used is set to ", num_cores, ".","\n"))
      BiocParallel::register(BiocParallel::bpstart(BiocParallel::MulticoreParam(num_cores)))
    }
    
    if (c1) {
      raw_data <-
        suppressMessages(read.MSdata(
          files = files,
          pdata = new("NAnnotatedDataFrame", pd),
          mode = mode,
          msLevel. = 1
        ))
      
      if(plan_switch){
        cache.save(raw_data, funpartnm = "data_import_c1");
        marker_record("data_import_c1");
      }
 
    } else {
      raw_data <- cache.read ("data_import", "c1")
      marker_record("data_import_1")
    }
    
    MessageOutput(NULL, NULL, 22)
    
    if (c2) {
      if (plotSettings$Plot == TRUE) {
        if (is.null(plotSettings$plot.opts)) {
          plot.opts <- "default"
        } else {
          plot.opts <- plotSettings$plot.opts
        }
        
        if (plot.opts == "default") {
          #subset raw_data to first 50 samples
          cat("To reduce memory usage BPIS and TICS plots will be created using only 10 samples per group.\n")
          
          grp_nms <- names(table(pd$sample_group))
          files <- NA
          
          for (i in 1:length(grp_nms)) {
            numb2ext <- min(table(pd$sample_group)[i], 10)
            filt_df <- pd[pd$sample_group == grp_nms[i], ]
            files.inx <- sample(nrow(filt_df), numb2ext)
            sel.samples <- filt_df$sample_name[files.inx]
            files <-
              c(files, which(pd$sample_name %in% sel.samples))
          }
          
          raw_data_filt <-
            filterFile(raw_data, file = na.omit(files))
          
        } else{
          raw_data_filt <- raw_data
          # just for plotting
        }
        
        #save(raw_data_filt, file = "raw_data_filt.rda")
        
        if (plot.opts == "all") {
          h <-
            readline(prompt = "Using all samples to create BPIS and TICS plots may cause severe memory issues! Press [0] to continue, or [1] to cancel: ")
          h <- as.integer(h)
          
          if (h == 1) {
            cat("ImportRawMSData function aborted!\n")
            return(0)
          }
        }
        
        cat("Plotting BPIS and TICS.\n")
        # Plotting functions to see entire chromatogram
        bpis <- chromatogram(raw_data_filt, aggregationFun = "max")
        tics <- chromatogram(raw_data_filt, aggregationFun = "sum")
        
        groupNum <- nlevels(groupInfo)
        
        if (groupNum > 9) {
          col.fun <-
            grDevices::colorRampPalette(RColorBrewer::brewer.pal(12, "Set3"))
          group_colors <- col.fun(groupNum)
          
        } else{
          group_colors <-
            paste0(RColorBrewer::brewer.pal(9, "Set1")[1:groupNum], "60")
        }
        
        names(group_colors) <- levels(groupInfo)
        
        bpis_name <-
          paste("BPIS_",
                plotSettings$dpi,
                ".",
                plotSettings$format,
                sep = "")
        
        tics_name <-
          paste("TICS_",
                plotSettings$dpi,
                ".",
                plotSettings$format,
                sep = "")
        
        #save(bpis, file = "bpis.rda"); # Don't need bpis for now.
        save(tics, file = "tics.rda")
        
        Cairo::Cairo(
          file = bpis_name,
          unit = "in",
          dpi = plotSettings$dpi,
          width = 8,
          height = 6,
          type = plotSettings$format,
          bg = "white"
        )
        
        plot(bpis, col = group_colors[raw_data_filt$sample_group])
        legend(
          "topright",
          legend = levels(groupInfo),
          pch = 15,
          col = group_colors
        )
        
        dev.off()
        
        Cairo::Cairo(
          file = tics_name,
          unit = "in",
          dpi = plotSettings$dpi,
          width = 8,
          height = 6,
          type = plotSettings$format,
          bg = "white"
        )
        
        plot(tics, col = group_colors[raw_data_filt$sample_group])
        legend(
          "topright",
          legend = levels(groupInfo),
          pch = 15,
          col = group_colors
        )
        
        dev.off()
      }
      if (plan_switch) {
        marker_record("data_import_c2")
      }
    }
    
    MessageOutput(
      mes = paste0(
        "Step 2/6: Successfully imported raw MS data! (",
        Sys.time(),
        ") \nGoing to the next step..."
      ),
      ecol = "\n",
      progress = 24
    )
    
    if(mode == "onDisk"){
      mSet@rawOnDisk <- raw_data;
    } else if( mode == "inMemory"){
      mSet@rawInMemory <- raw_data;
    }
      
    return(mSet)
  }

read.MSdata <- function(files, 
                        pdata = NULL, 
                        msLevel. = NULL, 
                        centroided. = NA,
                        smoothed. = NA, 
                        cache. = 1L,
                        mode = c("inMemory", "onDisk")) {
  mode <- match.arg(mode)
  ## o normalize the file path, i.e. replace relative path with absolute
  ##   path. That fixes possible problems on Windows with SNOW parallel
  ##   processing and also proteowizard problems on unis system with ~ paths.
  files <- normalizePath(files)
  suppressWarnings(.hasChroms <- MSnbase::hasChromatograms(files))
  
  MessageOutput ("Raw file import begin...", "\n", NULL)
  
  if (!length(files)) {
    process <- new("MSnProcess",
                   processing = paste("No data loaded:", date()))
    if (mode == "inMemory")
      res <- new("MSnExp",
                 processingData = process)
    else res <- new("OnDiskMSnExp",
                    processingData = process)
  } else {
    if (mode == "inMemory") {
      if (is.null(msLevel.)) msLevel. <- 2L
      res <- read.InMemMSd.data(files, pdata = pdata, msLevel. = msLevel.,
                                centroided. = centroided., smoothed. = smoothed., cache. = cache.)
    } else { ## onDisk
      res <- read.OnDiskMS.data(files = files, pdata = pdata,
                                msLevel. = msLevel., centroided. = centroided., smoothed. = smoothed.)
    }
  }
  res
}

#' @import utils
read.InMemMSd.data <- function(files, 
                               pdata, 
                               msLevel., 
                               centroided., 
                               smoothed., 
                               cache. = 1) {
  MSnbase:::.testReadMSDataInput(environment())
  if (MSnbase:::isCdfFile(files)) {
    #message("Polarity can not be extracted from netCDF files, please set ",
    #        "manually the polarity with the 'polarity' method.")
    msLevel. <- 1;
  }
  
  if (msLevel. == 1) cache. <- 0
  msLevel. <- as.integer(msLevel.)
  ## Creating environment with Spectra objects
  assaydata <- new.env(parent = emptyenv())
  ioncount <- c()
  ioncounter <- 1
  filenams <- filenums <- c()
  fullhd2 <- fullhdorder <- c()
  fullhdordercounter <- 1
  .instrumentInfo <- list()
  ## List eventual limitations
  
  ## ## Idea:
  ## ## o initialize a featureData-data.frame,
  ## ## o for each file, extract header info and put that into
  ##      featureData;
  
  count.idx <- 0;
  
  for (f in files) {
    cat(paste("Reading MS from",basename(f),"...\n"))
    
    filen <- match(f, files)
    filenums <- c(filenums, filen)
    filenams <- c(filenams, f)
    ## issue #214: define backend based on file format.
    msdata <- mzR::openMSfile(f,backend = NULL)
    .instrumentInfo <- c(.instrumentInfo, list(mzR::instrumentInfo(msdata)))
    fullhd <- mzR::header(msdata)
    ## Issue #325: get centroided information from file, but overwrite if
    ## specified with centroided. parameter.
    if (!is.na(centroided.))
      fullhd$centroided <- as.logical(centroided.)
    spidx <- which(fullhd$msLevel == msLevel.)
    ## increase vectors as needed
    ioncount <- c(ioncount, numeric(length(spidx)))
    fullhdorder <- c(fullhdorder, numeric(length(spidx)))
    if (msLevel. == 1) {
      if (length(spidx) == 0)
        stop("No MS1 spectra in file",f)
      
      
      if (.on.public.web){   
        print_mes <- paste0("Importing ",basename(f),":");    
        write.table(print_mes,file="metaboanalyst_spec_proc.txt",append = T,row.names = F,col.names = F, quote = F, eol = " ");
      }
      else {
        pb <- progress_bar$new(format = "Reading [:bar] :percent Time left: :eta", 
                               total = length(spidx), clear = T, width= 75)
      }
      
      k_count <- 0;
      for (i in 1:length(spidx)) {
        
        if (!.on.public.web){   
          pb$tick();
        }
        
        if (.on.public.web){  
          if (round(i/length(spidx),digits = 4)*100 - k_count > -0.2){
            print_mes <- paste0(k_count,"% | ");    
            write.table(print_mes,file="metaboanalyst_spec_proc.txt",append = T,row.names = F,col.names = F, quote = F, eol = " ");
            k_count <- k_count +20;
          }
          
        }
        
        j <- spidx[i]
        hd <- fullhd[j, ]
        ## Fix missing polarity from netCDF
        pol <- hd$polarity
        if (length(pol) == 0)
          pol <- NA
        .p <- mzR::peaks(msdata, j)
        sp <- new("Spectrum1",
                  rt = hd$retentionTime,
                  acquisitionNum = as.integer(hd$acquisitionNum),
                  scanIndex = as.integer(hd$seqNum),
                  tic = hd$totIonCurrent,
                  mz = .p[, 1],
                  intensity = .p[, 2],
                  fromFile = as.integer(filen),
                  centroided = as.logical(hd$centroided),
                  smoothed = as.logical(smoothed.),
                  polarity = as.integer(pol))
        ## peaksCount
        ioncount[ioncounter] <- sum(.p[, 2])
        ioncounter <- ioncounter + 1
        .fname <-MSnbase:::formatFileSpectrumNames(fileIds=filen,
                                                   spectrumIds=i,
                                                   nSpectra=length(spidx),
                                                   nFiles=length(files))
        assign(.fname, sp, assaydata)
        fullhdorder[fullhdordercounter] <- .fname
        fullhdordercounter <- fullhdordercounter + 1
      }
    } else { ## .msLevel != 1
      if (length(spidx) == 0)
        stop("No MS(n>1) spectra in file", f)
      cat(paste("Reading ", length(spidx), " MS", msLevel.,
                  " spectra from file ", basename(f),"\n"))
      
      scanNums <- fullhd[fullhd$msLevel == msLevel., "precursorScanNum"]
      if (length(scanNums) != length(spidx))
        stop("Number of spectra and precursor scan number do not match!")
      
      pb <- progress_bar$new(format = "Reading [:bar] :percent Time left: :eta", 
                             total = length(spidx), clear = T, width= 75)
      
      for (i in 1:length(spidx)) {
        
        pb$tick();
        
        j <- spidx[i]
        hd <- fullhd[j, ]
        .p <- mzR::peaks(msdata, j)
        sp <- new("Spectrum2",
                  msLevel = as.integer(hd$msLevel),
                  merged = as.numeric(hd$mergedScan),
                  precScanNum = as.integer(scanNums[i]),
                  precursorMz = hd$precursorMZ,
                  precursorIntensity = hd$precursorIntensity,
                  precursorCharge = as.integer(hd$precursorCharge),
                  collisionEnergy = hd$collisionEnergy,
                  rt = hd$retentionTime,
                  acquisitionNum = as.integer(hd$acquisitionNum),
                  scanIndex = as.integer(hd$seqNum),
                  tic = hd$totIonCurrent,
                  mz = .p[, 1],
                  intensity = .p[, 2],
                  fromFile = as.integer(filen),
                  centroided = as.logical(hd$centroided),
                  smoothed = as.logical(smoothed.),
                  polarity = as.integer(hd$polarity))
        ## peaksCount
        ioncount[ioncounter] <- sum(.p[, 2])
        ioncounter <- ioncounter + 1
        .fname <- MSnbase:::formatFileSpectrumNames(fileIds=filen,
                                                    spectrumIds=i,
                                                    nSpectra=length(spidx),
                                                    nFiles=length(files))
        assign(.fname, sp, assaydata)
        fullhdorder[fullhdordercounter] <- .fname
        fullhdordercounter <- fullhdordercounter + 1
      }
    }
    if (cache. >= 1)
      fullhd2 <- rbind(fullhd2, fullhd[spidx, ])
    
    gc()
    mzR::close(msdata)
    rm(msdata);
    
    if (.on.public.web){ 
      print_mes <- paste0("Done!");    
      write.table(print_mes,file="metaboanalyst_spec_proc.txt",append = T,row.names = F,col.names = F, quote = F, eol = "\n");
      
      count.idx <- count.idx + 1;  
      write.table(1.0 + count.idx/length(files)*3, file = paste0(fullUserPath, "log_progress.txt"),row.names = F,col.names = F);
    }
    
    cat(paste0("Reading from ", basename(f), " finished successfully !\n"));
    
  }
  
  ## cache level 2 yet implemented
  cache. <- MSnbase:::testCacheArg(cache., maxCache = 2)
  if (cache. >= 1) {
    fl <- sapply(assaydata, function(x) x@fromFile)
    featnms <- ls(assaydata) ## feature names in final MSnExp
    fl <- fl[featnms] ## reorder file numbers
    stopifnot(all(base::sort(featnms) == base::sort(fullhdorder)))
    fullhdorder <- match(featnms, fullhdorder)
    tmphd <- fullhd2[fullhdorder, ] ## reorder
    ioncount <- ioncount[fullhdorder]
    newhd <- data.frame(fileIdx = fl,
                        retention.time = tmphd$retentionTime,
                        precursor.mz = tmphd$precursorMZ,
                        precursor.intensity = tmphd$precursorIntensity,
                        charge = tmphd$precursorCharge,
                        peaks.count = tmphd$peaksCount,
                        tic = tmphd$totIonCurrent,
                        ionCount = ioncount,
                        ms.level = tmphd$msLevel,
                        acquisition.number = tmphd$acquisitionNum,
                        collision.energy = tmphd$collisionEnergy)
  } else {
    newhd <- NULL ## not used anyway
  }
  .cacheEnv <- MSnbase:::setCacheEnv(list("assaydata" = assaydata,
                                          "hd" = newhd),
                                     cache., lock = TRUE)
  ## CACHING AS BEEN SUPERSEDED BY THE OnDiskMSnExp IMPLEMENTATION
  ## if cache==2, do not lock assign msdata in .cacheEnv then lock
  ## it and do not close(msdata) above; rm(msdata) is OK
  
  ## Create 'MSnProcess' object
  process <- new("MSnProcess",
                 processing = paste("Data loaded:", date()),
                 files = files,
                 smoothed = smoothed.)
  ## Create 'fdata' and 'pdata' objects
  nms <- ls(assaydata)
  if (is.null(pdata)) {
    .pd <- data.frame(sampleNames = basename(files))
    rownames(.pd) <- .pd$sampleNames
    pdata <- new("AnnotatedDataFrame",
                 data = .pd)
  }
  fdata <- new("AnnotatedDataFrame",
               data = data.frame(
                 spectrum = 1:length(nms),
                 row.names = nms))
  fdata <- fdata[ls(assaydata)] ## reorder features
  ## expriment data slot
  if (length(.instrumentInfo) > 1) {
    cmp <- length(unique(sapply(.instrumentInfo, "[[", 1)))
    if (cmp > 1)
      message("According to the instrument information in the files,\n",
              "the data has been acquired on different instruments!")
    for (nm in names(.instrumentInfo[[1]]))
      .instrumentInfo[[1]][[nm]] <- sapply(.instrumentInfo, "[[", nm)
  }
  expdata <- new("MIAPE",
                 instrumentManufacturer = .instrumentInfo[[1]]$manufacturer,
                 instrumentModel = .instrumentInfo[[1]]$model,
                 ionSource = .instrumentInfo[[1]]$ionisation,
                 analyser = as.character(.instrumentInfo[[1]]$analyzer),
                 detectorType = .instrumentInfo[[1]]$detector)
  ## Create and return 'MSnExp' object
  
  toReturn <- new("MSnExp",
                  assayData = assaydata,
                  phenoData = pdata,
                  featureData = fdata,
                  processingData = process,
                  experimentData = expdata,
                  .cache = .cacheEnv)
  return(toReturn)
}

read.OnDiskMS.data <- function(files, 
                               pdata, 
                               msLevel., 
                               centroided., 
                               smoothed.) {
  
  MSnbase:::.testReadMSDataInput(environment())
  stopifnot(is.logical(centroided.))
  
  ## Creating environment with Spectra objects
  assaydata <- new.env(parent = emptyenv())
  filenams <- filenums <- c()
  fullhd2 <- fullhdorder <- c()
  fullhdordercounter <- 1
  .instrumentInfo <- list()
  ## List eventual limitations
  if (MSnbase:::isCdfFile(files)) {
    message("Polarity can not be extracted from netCDF files, please set ",
            "manually the polarity with the 'polarity' method.")
  }
  ## Idea:
  ## o initialize a featureData-data.frame,
  featureDataList <- list()
  ## o for each file, extract header info and put that into featureData
  ##pb <- progress_bar$new(format = "Reading [:bar] :percent Time left: :eta", 
  #                       total = length(spidx), clear = T, width= 75);
  
  count_mark <- 0;
  
  for (f in files) {
    
    if (.on.public.web){
      
      print_mes <- paste(basename(f),"import done!");    
      write.table(print_mes,file="metaboanalyst_spec_proc.txt",append = T,row.names = F,col.names = F, quote = F, eol = "\n");
      
    } else {
      #pb$tick();
    }    
    
    filen <- match(f, files)
    filenums <- c(filenums, filen)
    filenams <- c(filenams, f)
    ## issue #214: define backend based on file format.
    msdata <- mzR::openMSfile(f,backend = NULL)
    .instrumentInfo <- c(.instrumentInfo, list(mzR::instrumentInfo(msdata)))
    fullhd <- mzR::header(msdata)
    spidx <- seq_len(nrow(fullhd))
    
    ## Don't read the individual spectra, just define the names of
    ## the spectra.
    fullhdorder <- c(fullhdorder,
                     MSnbase:::formatFileSpectrumNames(fileIds=filen,
                                                       spectrumIds=seq_along(spidx),
                                                       nSpectra=length(spidx),
                                                       nFiles=length(files)))
    ## Extract all Spectrum info from the header and put it into the featureData
    fdData <- fullhd[spidx, , drop = FALSE]
    ## rename totIonCurrent and peaksCount, as detailed in
    ## https://github.com/lgatto/MSnbase/issues/105#issuecomment-229503816
    names(fdData) <- sub("peaksCount", "originalPeaksCount", names(fdData))
    ## Add also:
    ## o fileIdx -> links to fileNames property
    ## o spIdx -> the index of the spectrum in the file.
    fdData <- cbind(fileIdx = rep(filen, nrow(fdData)),
                    spIdx = spidx,
                    smoothed = rep(as.logical(smoothed.), nrow(fdData)),
                    fdData, stringsAsFactors = FALSE)
    if (MSnbase:::isCdfFile(f)) {
      ## Add the polarity columns if missing in netCDF
      if (!any(colnames(fdData) == "polarity"))
        fdData <- cbind(fdData, polarity = rep(as.integer(NA),
                                               nrow(fdData)))
    }
    ## Order the fdData by acquisitionNum to force use of acquisitionNum
    
    ## as unique ID for the spectrum (issue #103). That way we can use
    ## the spIdx (is the index of the spectrum within the file) for
    ## subsetting and extracting.
    if (!all(sort(fdData$acquisitionNum) == fdData$acquisitionNum))
      warning(paste("Unexpected acquisition number order detected.",
                    "Please contact the maintainers or open an issue",
                    "on https://github.com/lgatto/MSnbase.",
                    sep = "\n")) ## see issue #160
    fdData <- fdData[order(fdData$acquisitionNum), ]
    featureDataList <- c(featureDataList, list(fdData))
    ## Fix for #151; would be nice if we could remove that at some point.
    gc()
    mzR::close(msdata)
    rm(msdata)
  }
  ## new in version 1.9.8
  lockEnvironment(assaydata, bindings = TRUE)
  .cacheEnv <- MSnbase:::setCacheEnv(list("assaydata" = assaydata,
                                          "hd" = NULL),
                                     level = 0,
                                     lock = TRUE)
  
  ## Create 'MSnProcess' object
  process <- new("MSnProcess",
                 processing = paste0("Data loaded [", date(), "]"),
                 files = files,
                 smoothed = NA)
  ## Create 'fdata' and 'pdata' objects
  if (is.null(pdata)) {
    .pd <- data.frame(sampleNames = basename(files))
    rownames(.pd) <- .pd$sampleNames
    pdata <- new("AnnotatedDataFrame",
                 data = .pd)
  }
  ## If we've got a featureDataList, use it
  if (length(featureDataList) > 0) {
    fdata <- do.call(rbind, featureDataList)
    fdata <- cbind(fdata, spectrum = 1:nrow(fdata),
                   stringsAsFactors = FALSE)
    ## Setting rownames on the data.frame not on the AnnotatedDataFrame;
    ## did get strange errors otherwise.
    rownames(fdata) <- fullhdorder
    ## Re-order them
    fdata <- fdata[base::sort(fullhdorder), ]
    fdata <- new("AnnotatedDataFrame", data = fdata)
    ## Re-order the features.
    ## fdata <- fdata[ls(assaydata), ]
  } else fdata <- new("AnnotatedDataFrame")
  
  ## expriment data slot
  if (length(.instrumentInfo) > 1) {
    cmp <- length(unique(sapply(.instrumentInfo, "[[", 1)))
    if (cmp > 1)
      message("According to the instrument information in the files,\n",
              "the data has been acquired on different instruments!")
    for (nm in names(.instrumentInfo[[1]]))
      .instrumentInfo[[1]][[nm]] <- sapply(.instrumentInfo, "[[", nm)
  }
  expdata <- new("MIAPE",
                 instrumentManufacturer = .instrumentInfo[[1]]$manufacturer,
                 instrumentModel = .instrumentInfo[[1]]$model,
                 ionSource = .instrumentInfo[[1]]$ionisation,
                 analyser = as.character(.instrumentInfo[[1]]$analyzer),
                 detectorType = .instrumentInfo[[1]]$detector)
  ## Create ProcessingStep if needed.
  ## Create the OnDiskMSnExp object.
  res <- new("OnDiskMSnExp",
             assayData = assaydata,
             phenoData = pdata,
             featureData = fdata,
             processingData = process,
             experimentData = expdata,
             .cache  =  .cacheEnv)
  if (!is.null(msLevel.)) {
    msLevel. <- as.integer(msLevel.)
    res <- filterMsLevel(res, msLevel.)
  }
  if (any(!is.na(centroided.))) {
    if (length(centroided.) == 1) {
      centroided(res) <- centroided.
    } else {
      for (i in seq_along(centroided.))
        centroided(res, msLevel. = i) <- centroided.[i]
    }
  }
  
  if (.on.public.web){
    write.table("Raw file initialized Successfully!",file="metaboanalyst_spec_proc.txt",append = T,row.names = F,col.names = F, quote = F, eol = "\n");
  }
  
  return(res)
}

#' UpdateRawfiles
#' @description Update the Raw spectra included for Processing. All wrong format and uncentroided files will be filtered. 
#' NOTE: this function is only effective before data import stage.
#' @param mSet mSet objects generated with \"mSet<-InitDataObjects(\"spec\", \"raw\", FALSE)\";
#' @param filesIncluded filesIncluded is a vector containing the files' paths for the following processing;
#' @author Zhiqiang Pang \email{zhiqiang.pang@mail.mcgill.ca} and Jeff Xia \email{jeff.xia@mcgill.ca}
#' McGill University, Canada
#' License: GNU GPL (>= 2)
#' @export
#' @examples 
#' ## load googledrive package to download example data
#' # library("googledrive");
#' # data_folder_Sample <- "Raw_data_example"
#' # temp <- tempfile(fileext = ".zip");
#' ## Please authorize the package to download the data from web
#' # dl <- drive_download(as_id("1CjEPed1WZrwd5T3Ovuic1KVF-Uz13NjO"), path = temp, overwrite = TRUE);
#' # out <- unzip(temp, exdir = data_folder_Sample);
#' # out;
#' # library(OptiLCMS);
#' # mSet<-InitDataObjects("spec", "raw", FALSE);
#' ## include only two samples CD_SM-77FXR.mzML and CD_SM-6KUCT.mzML for data import.
#' # mSet<-UpdateRawfiles(mSet, c("Raw_data_example/CD/CD_SM-77FXR.mzML", 
#' #                      "Raw_data_example/CD/CD_SM-6KUCT.mzML"))

UpdateRawfiles <- function(mSet, filesIncluded = NULL){
  
  # TODO: to develope a shiny interface for user to select their files to include
  # if (interactive()) {
  #   
  #   options(shiny.maxRequestSize=400*1024^2) 
  #   
  #   ui <- fluidPage(
  #     titlePanel("Multiple Spectral file read"),
  #     sidebarLayout(
  #       sidebarPanel(
  #         fileInput("SpectralFiles", "Choose Spectra File", accept = c(".mzML",".mzXML","mzml","mzxml","mzData"),
  #                   multiple = TRUE),
  #         
  #       ),
  #       mainPanel(
  #         textOutput("count")
  #       )
  #     )
  #   )
  # 
  #   server <- function(input, output) {
  # 
  #     output$contents <- renderTable({
  #       file <- input$SpectralFiles
  #       ext <- tools::file_ext(file$datapath)
  # 
  #       req(file)
  #       validate(need(ext %in% c(".mzML",".mzXML","mzml","mzxml","mzData"), "Please upload a spectral file !"))
  # 
  #       file;
  #     })
  #     
  #     return(output)
  #   }
  #   
  #   shinyApp(ui, server)
  # }
  
  if(!is.null(filesIncluded)){
    
    # file exits check
    fileIdx <- file.exists(filesIncluded);
    if(!any(fileIdx)){
      stop("No valid files provided ! Please check !")
    }
    filesIncluded_exited <- filesIncluded[fileIdx];
    filesIncluded_full <- unname(sapply(filesIncluded_exited, tools::file_path_as_absolute));
    
    # file format check
    exts <- tools::file_ext(filesIncluded_full);
    extsIdx <- exts %in% c("mzML","mzXML","mzml","mzxml","mzData", "mzdata");
    if(!any(extsIdx)){
      stop("No valid format files provided ! Only files with extension of \"mzML\", \"mzml\", \"mzXML\", \"mzxml\", \"mzData\" and \"mzdata\" are supported!")
    }
    filesIncluded_formated <- filesIncluded_full[extsIdx];
    
    # file centroid check
    Centroididx <- unname(sapply(filesIncluded_formated, CentroidCheck));
    if(!any(Centroididx)){
      stop("No centroided spectrum found ! Please Centroid them first !")
    }
    filesIncluded_centroided <- filesIncluded_formated[Centroididx];
    message(paste0(filesIncluded_centroided, "will be included for further processing !"))
    
    # file size check
    fileSizeInfo <- file.size(filesIncluded_centroided)/1024^2;
    largeFileIdx <- fileSizeInfo > 200;
    if(any(fileSizeInfo)){
      message(paste0(filesIncluded_centroided[largeFileIdx]), "is larger than 200MB, please note your memory !")
    }
    
    filesIncluded <- filesIncluded_centroided;
    
  } else {
    warning("No files will be included for mSet !")
  }
  
  
  if(is.null(filesIncluded)){
    message("No files will be used to update the files inclusion for mSet!")
  }
  
  mSet@rawfiles <- filesIncluded;
  
  save(mSet, file = "mSet.rda");
  return(mSet);
}

#' Verify the data is centroid or not
#' @param filename single file name, should contain the absolute path
#' @author Zhiqiang Pang \email{zhiqiang.pang@mail.mcgill.ca} and Jeff Xia \email{jeff.xia@mcgill.ca}
#' McGill University, Canada
#' License: GNU GPL (>= 2)
#' @importFrom stats quantile
#' @export
#' @examples  
#' ## load googledrive package to download example data
#' # library("googledrive");
#' # data_folder_Sample <- "Raw_data_example"
#' # temp <- tempfile(fileext = ".zip");
#' ## Please authorize the package to download the data from web
#' # dl <- drive_download(as_id("1CjEPed1WZrwd5T3Ovuic1KVF-Uz13NjO"), path = temp, overwrite = TRUE);
#' # out <- unzip(temp, exdir = data_folder_Sample);
#' # out;
#' # library(OptiLCMS);
#' # mSet<-InitDataObjects("spec", "raw", FALSE);
#' ## input CD_SM-77FXR.mzML to check. TRUE means has been centroided well.
#' # res <- CentroidCheck("Raw_data_example/CD/CD_SM-77FXR.mzML")


CentroidCheck <- function(filename) {
  fileh <- MSnbase:::.openMSfile(filename)
  
  allSpect <- mzR::peaks(fileh, c(1:10))
  
  nValues <- base::lengths(allSpect, use.names = FALSE) / 2
  allSpect <- do.call(rbind, allSpect)
  
  res <- MSnbase:::Spectra1_mz_sorted(
    peaksCount = nValues,
    rt = c(1:10),
    acquisitionNum = c(1:10),
    scanIndex = c(1:10),
    tic = c(1:10),
    mz = allSpect[, 1],
    intensity = allSpect[, 2],
    fromFile = c(1:10),
    centroided = rep(NA, 10),
    smoothed =  rep(NA, 10),
    polarity =  rep(-1, 10),
    nvalues = nValues
  )
  names(res) <-
    paste0("F1.s100",
           c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10"))
  
  
  mzR::close(fileh)
  rm(fileh)
  
  res <- lapply(
    res,
    FUN = function(z, APPLF, ...) {
      pk <- as.data.frame(list(z))
      
      k = 0.025
      qtl = 0.9
      .qtl <- quantile(pk[, 2], qtl)
      x <- pk[pk[, 2] > .qtl, 1]
      quantile(diff(x), 0.25) > k
      
    }
  )
  
  return(sum(unlist(res)) > 8)
}

#' Set class information for MS data
#' @description This function sets the class information
#' for preprocessing MS data.
#' @param class class/group of samples.
#' @noRd
#' @author Jasmine Chong \email{jasmine.chong@mail.mcgill.ca},
#' Mai Yamamoto \email{yamamoto.mai@mail.mcgill.ca}, and Jeff Xia \email{jeff.xia@mcgill.ca}
#' McGill University, Canada
#' License: GNU GPL (>= 2)

SetClass <- function(class) {
  groupInfo <<- class
}

